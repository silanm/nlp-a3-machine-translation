{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation + Transformer\n",
    "\n",
    "<img src = \"figures/transformer1.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.0'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset\n",
    "\n",
    "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "SRC_LANGUAGE = \"en\"\n",
    "TRG_LANGUAGE = \"de\"\n",
    "\n",
    "train = Multi30k(split=(\"train\"), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardingFilterIterDataPipe"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so this is a datapipe object; very similar to pytorch dataset version 2 which is better\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Two young, White males are outside near many bushes.',\n",
       " 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at one example of train\n",
    "sample = next(iter(train))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 29001 is plenty,, we gonna call `random_split` to train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = train.random_split(total_length=train_size, weights={\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}, seed=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20301"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5800"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = len(list(iter(val)))\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2900"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = len(list(iter(test)))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n",
    "\n",
    "**Note**: the models must first be downloaded using the following on the command line: \n",
    "```\n",
    "python3 -m spacy download en_core_web_sm\n",
    "python3 -m spacy download de_core_news_sm\n",
    "```\n",
    "\n",
    "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spacy==3.7.6\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "token_transform[TRG_LANGUAGE] = get_tokenizer(\"spacy\", language=\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Two young, White males are outside near many bushes.\n",
      "Tokenization:  ['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "# example of tokenization of the english part\n",
    "print(\"Sentence: \", sample[0])\n",
    "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to tokenize our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample[language_index[language]])  # either first or second index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text to integers (Numericalization)\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(train, ln),\n",
    "        min_freq=2,  # if not, everything will be treated as UNK\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )  # indicates whether to insert symbols at the beginning or at the end\n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1891, 10, 4, 0, 4]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some example\n",
    "vocab_transform[SRC_LANGUAGE]([\"here\", \"is\", \"a\", \"unknownword\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can reverse it....\n",
    "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
    "\n",
    "# print 1816, for example\n",
    "mapping[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try unknown vocab\n",
    "mapping[0]\n",
    "# they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n",
    "\n",
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])))\n",
    "\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(\n",
    "        token_transform[ln],  # Tokenization\n",
    "        vocab_transform[ln],  # Numericalization\n",
    "        tensor_transform,\n",
    "    )  # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)  # <----need this because we use linear layers mostly\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, de in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([64, 24])\n",
      "German shape:  torch.Size([64, 27])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
    "print(\"German shape: \", de.shape)  # (batch_size, seq len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model\n",
    "\n",
    "<img src=\"figures/transformer-encoder.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src = [batch size, src len, hid dim]\n",
    "        # src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        # src: [batch_size, src len, hid dim]\n",
    "\n",
    "        _src = self.feedforward(src)\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        # src: [batch_size, src len, hid dim]\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length=100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src = [batch size, src len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "\n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        # pos: [batch_size, src_len]\n",
    "\n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        # src: [batch_size, src_len, hid_dim]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        # src: [batch_size, src_len, hid_dim]\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutli Head Attention Layer\n",
    "\n",
    "<img src = \"figures/transformer-attention.png\" width=\"700\">\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "\n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # src, src, src, src_mask\n",
    "        # query = [batch size, query len, hid dim]\n",
    "        # key = [batch size, key len, hid dim]\n",
    "        # value = [batch size, value len, hid dim]\n",
    "\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        # Q=K=V: [batch_size, src len, hid_dim]\n",
    "\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        # Q = [batch_size, n heads, query len, head_dim]\n",
    "\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        # Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
    "        # energy = [batch_size, n heads, query len, key len]\n",
    "\n",
    "        # for making attention to padding to 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        # attention = [batch_size, n heads, query len, key len]\n",
    "\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        # [batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
    "        # x = [batch_size, n heads, query len, head dim]\n",
    "\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  # we can perform .view\n",
    "        # x = [batch_size, query len, n heads, head dim]\n",
    "\n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        # x = [batch_size, query len, hid dim]\n",
    "\n",
    "        x = self.fc_o(x)\n",
    "        # x = [batch_size, query len, hid dim]\n",
    "\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, src len, hid dim]\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder Layer\n",
    "\n",
    "<img src = \"figures/transformer-decoder.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [batch size, trg len, hid dim]\n",
    "        # enc_src = [batch size, src len, hid dim]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        # trg = [batch_size, trg len, hid dim]\n",
    "\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        # trg = [batch_size, trg len, hid dim]\n",
    "        # attention = [batch_size, n heads, trg len, src len]\n",
    "\n",
    "        _trg = self.feedforward(trg)\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        # trg = [batch_size, trg len, hid dim]\n",
    "\n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length=100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [batch size, trg len]\n",
    "        # enc_src = [batch size, src len, hid dim]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        # pos: [batch_size, trg len]\n",
    "\n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        # trg: [batch_size, trg len, hid dim]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # trg: [batch_size, trg len, hid dim]\n",
    "        # attention: [batch_size, n heads, trg len, src len]\n",
    "\n",
    "        output = self.fc_out(trg)\n",
    "        # output = [batch_size, trg len, output_dim]\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together (become Seq2Seq!)\n",
    "\n",
    "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 1\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # src = [batch size, src len]\n",
    "\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # trg = [batch size, trg len]\n",
    "\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
    "        # trg_sub_mask = [trg len, trg len]\n",
    "\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "\n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src = [batch size, src len]\n",
    "        # trg = [batch size, trg len]\n",
    "\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        # src_mask = [batch size, 1, 1, src len]\n",
    "        # trg_mask = [batch size, 1, trg len, trg len]\n",
    "\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        # enc_src = [batch size, src len, hid dim]\n",
    "\n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # output = [batch size, trg len, output dim]\n",
    "        # attention = [batch size, n heads, trg len, src len]\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, \"weight\") and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
    "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(5174, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(6433, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=6433, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim = len(vocab_transform[TRG_LANGUAGE])\n",
    "hid_dim = 256\n",
    "enc_layers = 3\n",
    "dec_layers = 3\n",
    "enc_heads = 8\n",
    "dec_heads = 8\n",
    "enc_pf_dim = 512\n",
    "dec_pf_dim = 512\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX\n",
    "\n",
    "enc = Encoder(input_dim, hid_dim, enc_layers, enc_heads, enc_pf_dim, enc_dropout, device)\n",
    "\n",
    "dec = Decoder(output_dim, hid_dim, dec_layers, dec_heads, dec_pf_dim, enc_dropout, device)\n",
    "\n",
    "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324544\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "1646848\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "1646848\n",
      "  6433\n",
      "______\n",
      "8629537\n"
     ]
    }
   ],
   "source": [
    "# we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f\"{item:>6}\")\n",
    "    print(f\"______\\n{sum(params):>6}\")\n",
    "\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0005\n",
    "\n",
    "# training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)  # combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
    "\n",
    "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
    "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
    "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, src_len, trg in loader:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
    "        output, _ = model(src, trg[:, :-1])\n",
    "\n",
    "        # output = [batch size, trg len - 1, output dim]\n",
    "        # trg    = [batch size, trg len]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)  # trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
    "\n",
    "        # output = [batch size * trg len - 1, output dim]\n",
    "        # trg    = [batch size * trg len - 1]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, src_len, trg in loader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, _ = model(src, trg[:, :-1])\n",
    "\n",
    "            # output = [batch size, trg len - 1, output dim]\n",
    "            # trg = [batch size, trg len]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            # output = [batch size * trg len - 1, output dim]\n",
    "            # trg = [batch size * trg len - 1]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n",
    "\n",
    "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
    "\n",
    "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length = len(list(iter(valid_loader)))\n",
    "test_loader_length = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 19s\n",
      "\tTrain Loss: 4.200 | Train PPL:  66.703\n",
      "\t Val. Loss: 3.232 |  Val. PPL:  25.337\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "num_epochs = 1\n",
    "clip = 1\n",
    "\n",
    "save_path = f\"models/{model.__class__.__name__}.pt\"\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "\n",
    "    # for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}\")\n",
    "\n",
    "    # lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label=\"train loss\")\n",
    "ax.plot(valid_losses, label=\"valid loss\")\n",
    "plt.legend()\n",
    "ax.set_xlabel(\"updates\")\n",
    "ax.set_ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.210 | Test PPL:  24.775 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two young, White males are outside near many bushes.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,   19,   25,   15, 1069,  842,   17,   56,   84,  331, 1623,    5,\n",
       "           3], device='mps:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,   21,   83,  262,   32,   89,   22,   91,    7,   16,  115,    0,\n",
       "        2893,    4,    3], device='mps:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(1, -1)  # because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 13]), torch.Size([1, 15]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model(src_text, trg_text)  # turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 6433])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape  # batch_size, trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 6433])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 6433])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape  # trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1)  # returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 32,  32,  32,  58,   7,  91,   9,   6, 115,   4,   4,   4,   3,   4],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Männer\n",
      "Männer\n",
      "Männer\n",
      "spielen\n",
      "in\n",
      "Freien\n",
      ",\n",
      "einem\n",
      "Nähe\n",
      ".\n",
      ".\n",
      ".\n",
      "<eos>\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Attention\n",
    "\n",
    "Let's display the attentions to understand how the source text links with the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 15, 13])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 13])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = attentions[0, 0, :, :]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Two',\n",
       " 'young',\n",
       " ',',\n",
       " 'White',\n",
       " 'males',\n",
       " 'are',\n",
       " 'outside',\n",
       " 'near',\n",
       " 'many',\n",
       " 'bushes',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = [\"<sos>\"] + token_transform[SRC_LANGUAGE](sample[0]) + [\"<eos>\"]\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Männer',\n",
       " 'Männer',\n",
       " 'Männer',\n",
       " 'spielen',\n",
       " 'in',\n",
       " 'Freien',\n",
       " ',',\n",
       " 'einem',\n",
       " 'Nähe',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '<eos>',\n",
       " '.']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = [\"<sos>\"] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "\n",
    "    cax = ax.matshow(attention, cmap=\"bone\")\n",
    "\n",
    "    ax.tick_params(labelsize=10)\n",
    "\n",
    "    y_ticks = [\"\"] + translation\n",
    "    x_ticks = [\"\"] + sentence\n",
    "\n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/lpm_vt6d0xn9vpgr57mk29sc0000gn/T/ipykernel_71577/92231667.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "/var/folders/yw/lpm_vt6d0xn9vpgr57mk29sc0000gn/T/ipykernel_71577/92231667.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(y_ticks)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
